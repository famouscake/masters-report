% @TODO Change this
\chapter{Contour Trees}
\label{chapter3}

% @TODO Add reference.

The Reeb Graph of a contractable topological space is connected and acyclic \cite{comp-topo}. This allows us to define a special case of the Reeb Graph called the Contour Tree.  In this chapter we will assemble the theory we have presented thus far and use it to introduce the state of the art serial and parallel algorithms for contour tree computation. We will begin with a short discussion on how we treat input data and what theoretical simplifying assumptions we are making. Afterwards we will present some graph theoretical properties of contour trees and then demonstrate how those are used in the construction of the algorithms. We will conclude with a discussion of a particular pathological case that causes poor performance in the parallel contour tree algorithm. In addition to this we will include the extra topic of contour tree simplification. Simplification is the process of identifying and removing parts of the contour tree that are not topologically significant.


\section{Typical Data}

% @TODO Add this back if you have the time.

% Such a process is for example the sampling of temperature from a bounded volume of air [] or the height of points over a geographic region []. The contour tree is shown to be a robust tool primarily used in the visualisation of such natural phenomena [].


Many scientific and medical applications require the sampling of points from a bounded area or volume in two or three dimensional Euclidean space \cite{carr-masters}. The theory we have presented so far is applicable only in the continuous setting but the resolution of any sampling process is finite. If we are to leverage this theory we must assume an underlying continuous function in the whole of the area or volume and not just at the sampled points. To do so we will construct an approximation of this function based on the values we have sampled. This is usually done by constructing a simplicial complex where the data points are the vertices and higher dimensional simplicies are added to completely fill the space between them (see Figure []). The resulting data structure we will call a simplical mesh \cite{carr-masters}.

\begin{figure}[h]%
    \centering
    \subfloat[Input Data]{{\includegraphics[scale=0.4]{./images/w3x3-vertices.eps}}}%
    \qquad \qquad \qquad
    \subfloat[Simplicial Mesh]{{\includegraphics[scale=0.4]{./images/w3x3-mesh.eps}}}%
    \caption{Triangulation of input data to obtain a simplicial mesh.}%
    \label{fig:example}%
\end{figure}

The values of the approximation function at the simplicies are obtained via linear interpolation between the verticies of each simplex. As long as the original values we have sampled are unique it can be shown that the resulting linear interpolation function is a Morse function and that the critical values are critical points are the vertices of the mesh \cite{curvature-embeded-polyhedra}.We will demonstrate in the following section how this crucial property enables efficient computation.

\section{Algorithms for Computing Contour Trees}

The first efficient algorithm for constructing contour trees \cite{first-ct-algo} is due to Van Kreveld et al. Its running time is $O(NlogN)$ on two dimensional domains and $O(N^2)$ in higher dimensions where $N$ is the number of triangles in the simplicial mesh. Tarasov and Vyalyi \cite{second-ct-algo} extended this algorithm to work in time $O(NlogN)$ in three dimensional domains. Their approach however involved a complicated procedure for dealing with multi-saddle points. Both algorithms suffer from lack of generality and non-trivial treatment of multi-saddle points. Shortly after Carr at. al \cite{ct-big-paper} introduced an algorithm with running time $O(nlogn + N\alpha(N))$ where $n$ is the number of vertices in the simplicial mesh and $\alpha$ is the notoriously slow growing inverse Ackerman function. This algorithm has the advantage that it works in any number of dimensions and has simple treatment of multi-saddle points.

More recent developments in the field focus on extending the existing algorithms to accomodate the distributed \cite{distributed-ct-algo, distributed-ct-algo-2} and shared memory parallelism paradigms \cite{parallel-peak-pruning, parallel-ct-1}. The focus of this dissertation we will be one of the latest devlopments in the creating a data parallel shared memory algorithm for contour tree computation
\cite{parallel-peak-pruning}. Before introducing how that algorithm operates and one of the issues related to its parallel performance we will first give a more detailed overview on the most established serial algorithm \cite{ct-big-paper} which the data parallel one is based on. In order to talk about any of two algorithm however we must establish some notation and define height graphs and trees as they are defined in \cite{carr-masters}.

% @TODO Finish this.
% Also define regular points!

\section{Height Trees}

% @TODO Talk about supernodes and superarcs

% @TODO Target application domain.
A height graph is a graph $G = (V, E)$ together with a real valued function $h$ defined on the vertices of $G$. Height graphs are also known in the literature as weighted graphs. We are changing our notation to be more indicative of our target application domain. A height tree is a height graph which is a tree. Contour trees are height trees because nodes in the contour tree correspond to nodes in the mesh and we can consider their sampled value. Analogous to the assumption we have made about uniqueness of values we will also assume all vertices in the height trees we consider have unique heights. In other words $h(u) \ne h(v)$ for all $u ,v \in V(G)$ where $u \ne v$. The function $h$ naturally induces a total ordering on the vertices. From now on we will assume the vertices of $G$ are given in ascending order. That is to say, $V(G) = \{v_1, v_2, ... , v_n\}$ where $h(v_1) < h(v_2) < ... < h(v_n)$. This lets us work with the indices of the vertices without having to compare their heights directly. In this notation $h(v_i) < h(v_j)$ when $i < j$.

%@TODO Remove this if you will not use it.

Introducing the height function allows us to talk about ascending and descending paths. A path in the graph is a sequence of vertices $(u_1, u_2, ... , u_k)$ where $u_i \in V(G)$ for $i \in \{1, 2, ..., k\}$ and $u_iu_{i+1} \in E(G)$ for $i \in \{1, 2, ..., k-1\}$. Furthermore a path in a height graph is ascending whenever $h(u_1) < h(u_2) < ... < h(u_k)$. Conversely if we traverse the path in the opposite direction it would be descending. We will simply call these paths monotone whenever we wish to avoid committing to a specific direction of travel.

When working with height graphs it is useful to extend the definition of a degree of a vertex by taking the height function into account.

\begin{defn} Let $G$ be a height graph and $v$ a vertex of $G$. The up degree of $v$ is defined as the number of neighbours with higher value. It is denoted as $\delta^+(v) = \big|\{ u \in N(v) : h(u) > h(v) \}\big|$.   \end{defn}

The down degree of $v$ is defined analogously as $\delta^-(v) = \big|\{ u \in N(v) : h(u) < h(v) \}\big|$. In the context of height trees the definitions of up and down degrees of a vertex allows us distinguish between two types of leaves - lower and upper leaves.
\begin{defn} Let $G$ be a height graph and $v$ a vertex of $G$. If  $\delta^+(v) = 1$ and $\delta^-(v) = 0$ then $v$ is a lower leaf.  \end{defn}

If $\delta^+(v) = 0$ and $\delta^-(v) = 1$ then $v$ is an upper leaf. We will see in the next chapter how differentiating between the two types of leaves is used in constructing the contour tree.

\section{Join and Split Trees}

% @TODO Add example
The contour tree contains information for two types of events - joining and splitting of contours. Based on this we can take a contour tree and derive from it two other height trees that each contain the information of joining and splitting separately. We will call these the join and split trees. The join tree contains information for the contours that join together and the split tree holds the information for the contours that split apart. See Figure []. The join tree of a contour tree summarises the evolution of the connectivity of the sublevel sets of the interpolation function and the split tree of the superlevel sets. The two are symmetric in that the join tree of the function $f$ is isomorphic to the split tree of the negative of the function $-f$. You can find an example of the join and split trees of Figure [] on Figure [].


\begin{figure}[h]%
    \centering
    \subfloat[Simplicial Mesh]{{\includegraphics[scale=0.06]{./images/filtration/asc/x9.eps}}}%
    \qquad \qquad \qquad
    \subfloat[Contour Tree]{{\includegraphics[scale=0.10]{./images/w3x3-contour-tree-new.eps}}}%
    \qquad \qquad \qquad

    \subfloat[Join Tree]{{\includegraphics[scale=0.10]{./images/w3x3-join-tree-new.eps}}}%
    \qquad \qquad \qquad
    \subfloat[Split Tree]{{\includegraphics[scale=0.10]{./images/w3x3-split-tree-new.eps}}}%
    \caption{The Simplicial Mesh, Join and Split Trees and Contour Tree.}%
    \label{fig:mesh-join-split-contour}%
\end{figure}

The reason we would like to study join and split tree is that the contour tree can be reconstructed from them. The core idea of the algorithm we will present is that we can derives the join and split trees directly from the simplicial mesh and then combine them to obtain the contour tree. Let us first examine how join and split trees are computed from the mesh. We will describe for the process solely for the join tree. The computational for the split tree is completely analogous.  We first need the following definition.

\begin{defn} A join component is a connected component in the sublevel set $f^{-1}(\{h\})$ at some $h \in \mathbb{R}$.  \end{defn}

Let $M$ be our simplicial mesh and $h : M \to \mathbb{R}$ be the interpolation function defined on it. To construct the join tree we are going to have to keep track of which components merge together in the sublevels sets of $h$. We will consider all sublevel sets $M_t = h^{-1}((-\infty, t]) = \{x \in M : h(x) \in (-\infty, t] \}$ as a one parameter family $\{M_t\}_{t \in \mathbb{R}}$ of nested subsets of $M$. We can see from this definition that $M_a \subseteq M_b$ whenever $a \le b$. What the join tree captures is how the connectivity of the sublevel sets changes as the parameter $t$ is increased. The connectivity of sublevel sets changes either at local minima where a new component is created or a saddle point that merges two join components.

%We will not formalise the notion of tracking join components and constructing a join tree. Let us work in the general setting where $X$ is any path-connected topological space and $h : X \to \mathbb{R}$ is a function defined on $X$. The claims we make will hold in the special case where $X$ is a simplicial complex. Let us consider all sublevel sets $X_t = h^{-1}((-\infty, t]) = \{x \in X : h(x) \in (-\infty, t] \}$. They form a one parameter family $\{X_t\}_{t \in \mathbb{R}}$ of nested subsets where $X_a \subseteq X_b$ whenever $a \le b$. What the join tree captures is how the connectivity of the sublevel sets changes as the parameter $t$ is increased.

To visualise this process we can contract every join component to a point much like we did in the Reeb graph. The only difference here is that the equivalence relation is defined for all points in a sublevel set $h^{-1}((-\infty, t])$ instead of a level set $h^{-1}(\{t\})$. Because of this change and because join components can only merge the join tree is a tree \cite{comp-topo}. Furthermore if $M_m = M$ is the last sublevel set for some $m \in \mathbb{R}$ then all join components merge into one because $M$ is path connected.

% * Here is a beautiful example of this. *

% @TODO Add citation

We will briefly outline the algorithm for constructing the join tree and refer the reader to \cite{ct-big-paper} for further implementational details. The algorithm works by considering the vertices of the simplicial mesh in ascending order of height. If the current vertex is a local minimum we directly add it as a vertex in the join tree because it starts a join component. If the current vertex is a saddle that joins two or more components (join saddle) we add it to the join tree and add an edge between it and the local minima of the join components it merges. At the end of the computation all vertices will be in the same join component. In order to keep track of which join components different vertices belong to we can use the union-find data structure. This is exactly there the $\alpha(n)$ term in the time complexity of the algorithm comes from.

% @TODO Define Join Saddles and Subdivided edges
Not all vertices of the mesh will be in the join tree. Only those which correspond to local minima and to join saddles. This will pose a problem later on when we wish to combine the join and split trees. To avoid this problem we can augment the join tree by adding all missing vertices. This is done through edge subdivision. Let $a \text{ and } b$ be two adjacent vertices in the join tree.  Let $\{v_1, v_2, ..., v_n\}$ be vertices in the mesh that are not in the join tree that are given in ascending order in terms of height.  Suppose that $h(a) < h(v_i) < h(b)$ for all $i \in \{1, 2, ..., n\}$ and the vertices $v_i$ are in the same connected component of $X_b - h^{-1}(\{b\}) = h^{-1}((-\infty, b))$. In order to augment the join tree with the first vertex we subdivide the edge $ab$ and label the new vertex as $v_1$. Next we subdivide $v_1b$ and label the new vertex as $v_2$. We continue to do so and on the $k$th step we subdivide the edge
$ v_{k-1}b $ and label the new vertex as .

* Show some pretty pictures join, aug join, split, aug split, contour, aug contour*

The procedure of augmentation can be applied to the contour tree as well. We can use it to augment the contour tree with all vertices of the mesh which are not critical points. This is why we will differentiate between the contour tree and the augmented contour tree.

The second step of the algorithm is to combine the join and split trees to produce the contour tree. We will in fact be combining the augmented join tree with the augmented split tree to obtain the augmented contour tree. Removing the augmentation of the contour tree is then left as an optional final step. The first step in merging the two it to identify all leaves of the contour tree and their incident edges. We can recognize them immediately from the join and split trees using the following property \cite{carr-masters}.

\begin{defn} Let $v$ be a vertex such that its up degree in the join tree is $0$, its down degree in the split tree is $1$ and $u$ is it's only down neighbour in the split tree. Then $v$ is an up leaf in the contour tree and $vu$ is an edge in the contour tree.  \end{defn}

We will make an analogous definition in the case of down leaves and their adjacent edges.

\begin{defn} Let $v$ be a vertex such that its up degree in the join tree is $1$, its down degree in the split tree is $0$ and $u$ is it's only down neighbour in the join tree. Then $v$ is a down leaf in the contour tree and $vu$ is an edge in the contour tree.  \end{defn}

% @TODO Is it really known as pruning leaves?

Now suppose that we have identified $v$ as a leaf and $vu$ as it's adjacent edge in the split or join tree. Another property \cite{carr-masters} tells us that if we perform vertex contraction on $v$ (remove $v$ and form clique from its neighbours) from the join, split and contour trees we obtain the join and split trees of the contour tree with $v$ removed. This allows us to iteratively reapeat this process until we have removed all vertices. We are allowed to do so because removing all leaves in a tree leaves the tree with at least one leaf if it is not empty where the algorithm will terminate. For a detailed example of this process we refer the reader to \cite{ct-big-paper}.

\section{Serial Algorithm}

The Serial algorithm for the construction of the contour tree is a summary of the results we outlined in the previous section. It works as follows:

\textbf{Step 1.} Read input data and convert it to a simplicial mesh.

\textbf{Step 2.} Compute the Join and Split Tree of the mesh.

\textbf{Step 3.} Iteratively remove leaves from the Join and Split tree and add them to the Contour Tree until the Join and Split trees are empty.

% @TODO Define regular vertices.
\textbf{Step 4.} Remove regular vertices of the contour tree if necessary.

\section{Parallel Algorithm}

The data parallel contour tree algorithm \cite{parallel-peak-pruning} is largely based on the theory we have established so far. The parallel approach borrows the two phase methodology of computing the join and split trees and then merging them. We will omit describing the process of parallelising join/split tree computation because it is involved and completely separate from the problem we aim to address. We will however describe in detail how the merge phase is parallelised.

In general the data-parallel paradigm works best when there are a large number of computational tasks to be carried out independently. Dependant tasks require some form of synchronisation and that is costly in terms of performance. If we observe the merge phase of the serial algorithm we will notice that removing a leaf is a local operation. It only involves a few of the vertices of the join and split trees. This means that once we identify all up and down leaves we can remove them all in parallel in a single iteration. The key problem to solve in the merge phase is to reduce the number of total iterations needed to remove all vertices from the join and split trees. Consequently the amount of parallelism in this computation is limited by the number of leaves at each iteration. For example a tree which is a path of length $n$ will take at least $n/2$ iterations and a tree with one central vertex and $n$ leaves adjacent to it will take only two iterations.

In a graph with no vertices of degree two at least half of the vertices are leaves. If we can ensure that there are no vertices of degree two at each iteration we will obtain logarithmic collapse in the number of vertices. To ensure this property holds the authors of \cite{parallel-peak-pruning} have come up with a way of batching multiple adjacent vertices of degree two in a single iteration. If there is a path in the tree from a leaf to a degree three or more vertex where all intermediary vertices are of degree two, they should be processed in the same iteration the leaf is processed. We will call such structures leaf chains. This is in effect equivalent to contracting all vertices in the tree of degree two at every pass. This leaves only leaves and vertices of degree three or higher and ensures logarithmic collapse.

The paper \cite{parallel-peak-pruning} outlines a way of batching leaf chains when the chain is a monotone path in the tree. An issue arises when the chain is not a monotone path and some of the vertices inside it have alternating height. The we can only batch monotone subpaths and not the whole path. The more zig zags there are in the path the less monotone paths there and the more iterations we will require. This effectively serialises computation along them.

When plotted according to height such chains forms a characteristic zig-zag pattern (see \cite{parallel-peak-pruning}). We will call such chains W-Structures. They are the core issue we are addressing in this dissertation. We would like to obtain a better understanding of them and how and why they affect computation. The first step to solving such a problem is understanding it. We believe that theoretically it is these W-Structure that most severely hinder computation in the merge phase of the algorithm. The next chapter will address this by developing algorithms that analyse contour trees and determine the largest W-Structures that is present in them.

The theoretical issue caused by the w-structures becomes evident in the algorithmic analysis of the parallel contour tree algorithm. According to that the key question in the merge phase of the algorithm is how many iterations are needed to collapse the contour tree. Each iterations takes $O(1)$ steps because all leaves can be processed in parallel and $O(t)$ work, where $t$ is the number of leaves. This leads to an overall complexity of $O(log(t))$ steps and $O(tlog^2(t)$ work if we assume that no w-structures are present. If however there is a w-structure with more "zig zags" than $log(t)$ then the authors of the paper claim that the best formal guarantee they can give for the steps is the diameter of the contour tree. One of our goals in analysing the w-structures is to provide a better bound than the diameter of the tree. We will demonstrate how this can be done by develping some new theory about the w-structures in Chapter [] and through an empirical analysis in Chapter [].


\section{Contour Tree Simplification}

Finally we will introduce the topic of contour tree simplification. A central problem in using contour trees in visualisation is simplifying their output and presenting only the most important parts to enable human comprehension. The complexity of a contour tree of a large enough data set could severly limits its use. This is why it is vital to employ techniques that simplify the contour trees by removing parts of them that correspond to less "significant" topological features or sampling noise and error.

% @TODO Add hamish phd thesis as generalisation?

One such technique is branch decomposition \cite{ct-branch-decomp}. Branch decomposition involves decomposing the contour tree into a set of edge-wise disjoint monotone paths (branches) which cover all edges of the tree. A trivial branch decomposition of any tree is obtained by taking every edge to be a separate branch. Furthermore a branch decomposition is hierarchical when there is exactly one branch that connects two leaves and every other branch connects a leaf to an interior node. An example of a hierarchical branch decomposition is shown in Figure \ref{fig:branch-decomp}.

The branches in this scheme represent pairs of critical points. This pairing of critical points forms the basis for a topological simplification. The topological simplification consists of removing branches that do not disconnect the tree. This produces a hierarchy of cancellations like in Figure \ref{fig:branch-decomp}. We define the persistence of a branch to be the bigger of the difference between it's end points and the persistence of it's children. Branches of high persistence reflect more prominent features in the tree. We apply the simplification by removing branches with low persistence that do not disconnect the tree.

The algorithm for producing the heirarchical branch decomposition of a contour tree is the following:

\begin{itemize}
    \item Identify all upper leafs that connect via branches to upwards saddles.
    \item Identify all lower leafs that connect via branches to downwards saddles.
    \item Those are candidate branches. Pick the one with the lowest persistence (difference of height between the leaf and the saddle).
    \item Remove that branch without removing the saddle.
    \item Continue this process untill a single branch that connect two leaves is all that remains. That is the master branch.
\end{itemize}

Let us for example construct the heirarchical branch decomposition of the contour tree from Figure \ref{fig:mesh-join-split-contour}. The first two candidate branches we identify are $5 - 2$ and with persistence $3$ and $3 - 8$ with persistence $5$. We take the branch with lower persistence $5 - 2$. In the next step the candiate branches are $0 - 4$ and with persistence $4$ and $3 - 8$ with persistence $5$. We will take $0 - 4$.
Afterwards the remaining candiate branches are $3 - 7$ with persistence $4$ and $3 - 8$ with persistence $5$. After removing $3 - 7$ in the final stage the only remaining branch is $1 - 8$. It is the master branch because it connects two leaves.
The produced pairs of critical points are $(2, 5), (0, 4), (3, 7)$ and $(1,8)$.

\begin{figure}%
    \centering
    \subfloat[Branch Decomposition.]{{\includegraphics[scale=0.11]{./images/w3x3-ct-decomp.eps}}}%
    \subfloat[Heirarchical view of the branches.]{{\includegraphics[scale=0.11]{./images/w3x3-ct-h-decomp.eps}}}%
    \caption{Branch Decomposition of the Contour tree from Figure \ref{fig:mesh-join-split-contour} [which subfigure?].}%
    \label{fig:branch-decomp}%
\end{figure}

Branch Decomposition is a form of topological simplification whose use is limited to the contour tree. In Chapter 6 we will present a more general topological simplification method called persistent homology. Our goal will be to express branch d`ecomposition in the framework of persistent homology and determine whether the two are equivalent.

% @TODO Todo talk about how this is used to remove noise and artifacts in data.

% @TODO Remove Stay Tuned
% The paper \cite{ct-branch-decomp} cites that the persistence defined in that way is similar to persistence first defined in \cite{persistence-original}. In Chapter N of this dissertation we will demonstrate that this claim is either incorrect of misleading. Stay tuned folks.
